{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a4c34b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成对距离矩阵:\n",
      "tensor([[0., 1., 4.],\n",
      "        [1., 0., 3.],\n",
      "        [4., 3., 0.]])\n",
      "邻居掩码:\n",
      "tensor([[False,  True, False],\n",
      "        [ True, False,  True],\n",
      "        [False,  True, False]])\n",
      "邻居间距离: tensor([1.0000, 1.0000, 3.0000, 3.0000, 1.0000, 1.0000, 3.0000, 3.0000])\n",
      "MAD_neighbor: tensor(2.)\n",
      "非邻居间距离: tensor([4., 4., 4., 4.])\n",
      "MAD_remote: tensor(4.)\n",
      "MADGap: tensor(2.)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 假设我们有一个简单的例子\n",
    "# 2帧，3个原子，嵌入维度为2\n",
    "node_ebd = torch.tensor([\n",
    "    # 第1帧\n",
    "    [[1.0, 0.0],   # 原子0\n",
    "     [2.0, 0.0],   # 原子1  \n",
    "     [5.0, 0.0]],  # 原子2\n",
    "    # 第2帧\n",
    "    [[1.1, 0.1],   # 原子0\n",
    "     [2.1, 0.1],   # 原子1\n",
    "     [5.1, 0.1]]   # 原子2\n",
    "])  # shape: [2, 3, 2]\n",
    "\n",
    "# 邻居列表：原子0的邻居是原子1，原子1的邻居是原子0和2\n",
    "nlist = torch.tensor([\n",
    "    # 第1帧\n",
    "    [[1, -1],      # 原子0的邻居：原子1\n",
    "     [0, 2],       # 原子1的邻居：原子0, 2\n",
    "     [1, -1]],     # 原子2的邻居：原子1\n",
    "    # 第2帧  \n",
    "    [[1, -1],      # 原子0的邻居：原子1\n",
    "     [0, 2],       # 原子1的邻居：原子0, 2\n",
    "     [1, -1]]      # 原子2的邻居：原子1\n",
    "])  # shape: [2, 3, 2]\n",
    "\n",
    "# 计算成对距离\n",
    "node_ebd_i = node_ebd.unsqueeze(2)  # [2, 3, 1, 2]\n",
    "node_ebd_j = node_ebd.unsqueeze(1)  # [2, 1, 3, 2]\n",
    "distances = torch.norm(node_ebd_i - node_ebd_j, dim=-1)\n",
    "print(\"成对距离矩阵:\")\n",
    "print(distances[0])  # 第1帧的距离矩阵\n",
    "# tensor([[0.0000, 1.0000, 4.0000],  # 原子0到所有原子的距离\n",
    "#         [1.0000, 0.0000, 3.0000],  # 原子1到所有原子的距离  \n",
    "#         [4.0000, 3.0000, 0.0000]]) # 原子2到所有原子的距离\n",
    "\n",
    "# 构建邻居掩码\n",
    "neighbor_mask = torch.zeros_like(distances, dtype=torch.bool)\n",
    "for frame_idx in range(2):\n",
    "    for atom_idx in range(3):\n",
    "        neighbors = nlist[frame_idx, atom_idx]\n",
    "        valid_neighbors = neighbors[(neighbors >= 0) & (neighbors < 3)]\n",
    "        if len(valid_neighbors) > 0:\n",
    "            neighbor_mask[frame_idx, atom_idx, valid_neighbors] = True\n",
    "\n",
    "print(\"邻居掩码:\")\n",
    "print(neighbor_mask[0])\n",
    "# tensor([[False,  True, False],  # 原子0的邻居：原子1\n",
    "#         [ True, False,  True],  # 原子1的邻居：原子0, 2\n",
    "#         [False,  True, False]]) # 原子2的邻居：原子1\n",
    "\n",
    "# 排除对角线\n",
    "eye_mask = torch.eye(3, dtype=torch.bool).unsqueeze(0).expand(2, -1, -1)\n",
    "valid_mask = ~eye_mask\n",
    "\n",
    "# 计算MAD_neighbor（邻居间距离）\n",
    "neighbor_mask_valid = neighbor_mask & valid_mask\n",
    "neighbor_distances = distances[neighbor_mask_valid]\n",
    "print(\"邻居间距离:\", neighbor_distances)\n",
    "# tensor([1.0000, 1.0000, 3.0000, 3.0000])  # 0-1, 1-0, 1-2, 2-1的距离\n",
    "mad_neighbor = neighbor_distances.mean()\n",
    "print(\"MAD_neighbor:\", mad_neighbor)  # 2.0\n",
    "\n",
    "# 计算MAD_remote（非邻居间距离）\n",
    "remote_mask = ~neighbor_mask & valid_mask\n",
    "remote_distances = distances[remote_mask]\n",
    "print(\"非邻居间距离:\", remote_distances)\n",
    "# tensor([4.0000, 4.0000])  # 0-2, 2-0的距离\n",
    "mad_remote = remote_distances.mean()\n",
    "print(\"MAD_remote:\", mad_remote)  # 4.0\n",
    "\n",
    "# 计算MADGap\n",
    "mad_gap = mad_remote - mad_neighbor\n",
    "print(\"MADGap:\", mad_gap)  # 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4f4ee08b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norms tensor([[[1.0000],\n",
      "         [2.0000],\n",
      "         [5.0000]],\n",
      "\n",
      "        [[1.1045],\n",
      "         [2.1024],\n",
      "         [5.1010]]])\n",
      "dot_products tensor([[[ 1.0000,  2.0000,  5.0000],\n",
      "         [ 2.0000,  4.0000, 10.0000],\n",
      "         [ 5.0000, 10.0000, 25.0000]],\n",
      "\n",
      "        [[ 1.2200,  2.3200,  5.6200],\n",
      "         [ 2.3200,  4.4200, 10.7200],\n",
      "         [ 5.6200, 10.7200, 26.0200]]])\n",
      "norm_products tensor([[[ 1.0000,  2.0000,  5.0000],\n",
      "         [ 2.0000,  4.0000, 10.0000],\n",
      "         [ 5.0000, 10.0000, 25.0000]],\n",
      "\n",
      "        [[ 1.2200,  2.3222,  5.6342],\n",
      "         [ 2.3222,  4.4200, 10.7242],\n",
      "         [ 5.6342, 10.7242, 26.0200]]])\n",
      "cosine_dist tensor([[[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[-1.1921e-07,  9.2763e-04,  2.5232e-03],\n",
      "         [ 9.2763e-04,  0.0000e+00,  3.9136e-04],\n",
      "         [ 2.5232e-03,  3.9136e-04,  5.9605e-08]]])\n",
      "tensor([[[ 1, -1],\n",
      "         [ 0,  2],\n",
      "         [ 1, -1]],\n",
      "\n",
      "        [[ 1, -1],\n",
      "         [ 0,  2],\n",
      "         [ 1, -1]]])\n",
      "neighbor_mask tensor([[[False, False, False],\n",
      "         [False, False, False],\n",
      "         [False, False, False]],\n",
      "\n",
      "        [[False, False, False],\n",
      "         [False, False, False],\n",
      "         [False, False, False]]])\n",
      "berghbor mask shape torch.Size([2, 3, 3])\n",
      "frame_idx 0\n",
      "atom_idx 0\n",
      "frame_idx 0\n",
      "atom_idx 1\n",
      "frame_idx 0\n",
      "atom_idx 2\n",
      "frame_idx 1\n",
      "atom_idx 0\n",
      "frame_idx 1\n",
      "atom_idx 1\n",
      "frame_idx 1\n",
      "atom_idx 2\n",
      "neighbor_mask tensor([[[False,  True, False],\n",
      "         [ True, False,  True],\n",
      "         [False,  True, False]],\n",
      "\n",
      "        [[False,  True, False],\n",
      "         [ True, False,  True],\n",
      "         [False,  True, False]]])\n",
      "mad_gap tensor(0.0009)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "# 假设我们有一个简单的例子\n",
    "# 2帧，3个原子，嵌入维度为2\n",
    "node_ebd = torch.tensor([\n",
    "    # 第1帧\n",
    "    [[1.0, 0.0],   # 原子0\n",
    "     [2.0, 0.0],   # 原子1  \n",
    "     [5.0, 0.0]],  # 原子2\n",
    "    # 第2帧\n",
    "    [[1.1, 0.1],   # 原子0\n",
    "     [2.1, 0.1],   # 原子1\n",
    "     [5.1, 0.1]]   # 原子2\n",
    "])  # shape: [2, 3, 2]\n",
    "\n",
    "# 邻居列表：原子0的邻居是原子1，原子1的邻居是原子0和2\n",
    "nlist = torch.tensor([\n",
    "    # 第1帧\n",
    "    [[1, -1],      # 原子0的邻居：原子1\n",
    "     [0, 2],       # 原子1的邻居：原子0, 2\n",
    "     [1, -1]],     # 原子2的邻居：原子1\n",
    "    # 第2帧  \n",
    "    [[1, -1],      # 原子0的邻居：原子1\n",
    "     [0, 2],       # 原子1的邻居：原子0, 2\n",
    "     [1, -1]]      # 原子2的邻居：原子1\n",
    "])  # shape: [2, 3, 2]\n",
    "    # 计算向量范数 |Hi|, |Hj|\n",
    "norms = torch.norm(node_ebd, p=2, dim=-1, keepdim=True)  # [nf, nloc, 1]\n",
    "print(\"norms\", norms)\n",
    "# 计算点积矩阵 Hi · Hj\n",
    "dot_products = torch.bmm(node_ebd, node_ebd.transpose(-1, -2))  # [nf, nloc, nloc]\n",
    "print(\"dot_products\", dot_products)\n",
    "# 计算范数乘积矩阵 |Hi| * |Hj|\n",
    "norm_products = torch.bmm(norms, norms.transpose(-1, -2))  # [nf, nloc, nloc]\n",
    "print(\"norm_products\", norm_products)\n",
    "# 余弦距离 = 1 - 余弦相似度\n",
    "cosine_dist = 1.0 - (dot_products / (norm_products + 1e-8))  # 加小值避免除零\n",
    "print(\"cosine_dist\", cosine_dist)\n",
    "\n",
    "# 基于nlist创建neighbor mask\n",
    "nframes, nloc, embed_dim = node_ebd.shape\n",
    "device = node_ebd.device\n",
    "print(nlist)\n",
    "neighbor_mask = torch.zeros_like(cosine_dist, dtype=torch.bool, device=device)\n",
    "print(\"neighbor_mask\", neighbor_mask)\n",
    "print(\"berghbor mask shape\", neighbor_mask.shape)\n",
    "# 利用现有的nlist填充neighbor关系\n",
    "for frame_idx in range(nframes):\n",
    "    for atom_idx in range(nloc):\n",
    "        print(\"frame_idx\", frame_idx)\n",
    "        print(\"atom_idx\", atom_idx)\n",
    "\n",
    "        neighbors = nlist[frame_idx, atom_idx]  # [nnei]\n",
    "        # 过滤有效邻居（排除padding的-1值）\n",
    "        valid_neighbors = neighbors[(neighbors >= 0) & (neighbors < nloc)]\n",
    "        if len(valid_neighbors) > 0:\n",
    "            neighbor_mask[frame_idx, atom_idx, valid_neighbors] = True\n",
    "print(\"neighbor_mask\", neighbor_mask)\n",
    "\n",
    "\n",
    "# 排除对角线元素（i=j的情况）\n",
    "eye_mask = torch.eye(nloc, dtype=torch.bool, device=device).unsqueeze(0).expand(nframes, -1, -1)\n",
    "neighbor_mask = neighbor_mask & (~eye_mask)  # M^neighbor_ii = 0 恒成立\n",
    "\n",
    "# 创建远程目标掩码：M^remote = ¬M^neighbor ∧ ¬I (非邻居且非对角线)\n",
    "remote_mask = (~neighbor_mask) & (~eye_mask)\n",
    "\n",
    "# === 公式3: D̄ᵢᵗᵍᵗ = Σⱼ Dᵢⱼᵗᵍᵗ / Σⱼ 1(Dᵢⱼᵗᵍᵗ) - 计算每个节点的平均距离 ===\n",
    "\n",
    "# 计算每个节点的平均邻居距离\n",
    "mad_neighbor_per_node = []  # 存储每个节点的D̄ᵢⁿᵉⁱᵍʰᵇᵒʳ\n",
    "\n",
    "for f in range(nframes):\n",
    "    for i in range(nloc):\n",
    "        # 获取节点i的邻居距离 Dᵢⱼⁿᵉⁱᵍʰᵇᵒʳ (j是i的邻居)\n",
    "        neighbor_distances_i = cosine_dist[f, i][neighbor_mask[f, i]]\n",
    "        \n",
    "        if len(neighbor_distances_i) > 0:\n",
    "            # D̄ᵢⁿᵉⁱᵍʰᵇᵒʳ = Σⱼ Dᵢⱼⁿᵉⁱᵍʰᵇᵒʳ / Σⱼ 1(Dᵢⱼⁿᵉⁱᵍʰᵇᵒʳ > 0)\n",
    "            avg_neighbor_dist_i = neighbor_distances_i.mean()\n",
    "            mad_neighbor_per_node.append(avg_neighbor_dist_i)\n",
    "\n",
    "# 计算每个节点的平均远程距离\n",
    "mad_remote_per_node = []  # 存储每个节点的D̄ᵢʳᵉᵐᵒᵗᵉ\n",
    "\n",
    "for f in range(nframes):\n",
    "    for i in range(nloc):\n",
    "        # 获取节点i的远程距离 Dᵢⱼʳᵉᵐᵒᵗᵉ (j不是i的邻居且j≠i)\n",
    "        remote_distances_i = cosine_dist[f, i][remote_mask[f, i]]\n",
    "        \n",
    "        if len(remote_distances_i) > 0:\n",
    "            # D̄ᵢʳᵉᵐᵒᵗᵉ = Σⱼ Dᵢⱼʳᵉᵐᵒᵗᵉ / Σⱼ 1(Dᵢⱼʳᵉᵐᵒᵗᵉ > 0)\n",
    "            avg_remote_dist_i = remote_distances_i.mean()\n",
    "            mad_remote_per_node.append(avg_remote_dist_i)\n",
    "\n",
    "# === 公式4: MADᵗᵍᵗ = Σᵢ D̄ᵢᵗᵍᵗ / Σᵢ 1(D̄ᵢᵗᵍᵗ) - 对节点平均距离再求平均 ===\n",
    "\n",
    "# MADⁿᵉⁱᵍʰᵇᵒʳ = Σᵢ D̄ᵢⁿᵉⁱᵍʰᵇᵒʳ / Σᵢ 1(D̄ᵢⁿᵉⁱᵍʰᵇᵒʳ)\n",
    "if len(mad_neighbor_per_node) > 0:\n",
    "    mad_neighbor = torch.stack(mad_neighbor_per_node).mean()\n",
    "else:\n",
    "    mad_neighbor = torch.tensor(0.0, device=device)\n",
    "\n",
    "# MADʳᵉᵐᵒᵗᵉ = Σᵢ D̄ᵢʳᵉᵐᵒᵗᵉ / Σᵢ 1(D̄ᵢʳᵉᵐᵒᵗᵉ)\n",
    "if len(mad_remote_per_node) > 0:\n",
    "    mad_remote = torch.stack(mad_remote_per_node).mean()\n",
    "else:\n",
    "    mad_remote = torch.tensor(0.0, device=device)\n",
    "\n",
    "# MADGap = MADʳᵉᵐᵒᵗᵉ - MADⁿᵉⁱᵍʰᵇᵒʳ\n",
    "mad_gap = mad_remote - mad_neighbor\n",
    "print(\"mad_gap\", mad_gap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d52bff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node_ebd_pt tensor([[[0.2028, 0.1567, 0.5198,  ..., 0.5832, 0.0840, 0.3441],\n",
      "         [0.2053, 0.1584, 0.5246,  ..., 0.5857, 0.0838, 0.3596],\n",
      "         [0.1926, 0.1502, 0.5139,  ..., 0.5794, 0.0786, 0.3462],\n",
      "         ...,\n",
      "         [0.2044, 0.1533, 0.4108,  ..., 0.4040, 0.1300, 0.3748],\n",
      "         [0.2143, 0.1613, 0.4193,  ..., 0.4090, 0.1362, 0.3807],\n",
      "         [0.2219, 0.1731, 0.4327,  ..., 0.4144, 0.1316, 0.3942]]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "node_ebd_pt shape torch.Size([1, 192, 128])\n",
      "eye_mask tensor([[[ True, False, False,  ..., False, False, False],\n",
      "         [False,  True, False,  ..., False, False, False],\n",
      "         [False, False,  True,  ..., False, False, False],\n",
      "         ...,\n",
      "         [False, False, False,  ...,  True, False, False],\n",
      "         [False, False, False,  ..., False,  True, False],\n",
      "         [False, False, False,  ..., False, False,  True]]], device='cuda:0')\n",
      "eye_mask shape torch.Size([1, 192, 192])\n",
      "valid_mask tensor([[[False,  True,  True,  ...,  True,  True,  True],\n",
      "         [ True, False,  True,  ...,  True,  True,  True],\n",
      "         [ True,  True, False,  ...,  True,  True,  True],\n",
      "         ...,\n",
      "         [ True,  True,  True,  ..., False,  True,  True],\n",
      "         [ True,  True,  True,  ...,  True, False,  True],\n",
      "         [ True,  True,  True,  ...,  True,  True, False]]], device='cuda:0')\n",
      "valid_mask shape torch.Size([1, 192, 192])\n",
      "cosine_dist tensor([[[ 0.0000e+00,  2.7955e-04,  2.3073e-04,  ...,  1.1344e-02,\n",
      "           1.0864e-02,  1.0453e-02],\n",
      "         [ 2.7955e-04,  1.7881e-07,  1.1134e-04,  ...,  1.1401e-02,\n",
      "           1.1029e-02,  1.0538e-02],\n",
      "         [ 2.3073e-04,  1.1134e-04,  0.0000e+00,  ...,  1.1132e-02,\n",
      "           1.0894e-02,  1.0565e-02],\n",
      "         ...,\n",
      "         [ 1.1344e-02,  1.1401e-02,  1.1132e-02,  ...,  1.1921e-07,\n",
      "           9.1910e-05,  3.0559e-04],\n",
      "         [ 1.0864e-02,  1.1029e-02,  1.0894e-02,  ...,  9.1910e-05,\n",
      "           0.0000e+00,  9.8467e-05],\n",
      "         [ 1.0453e-02,  1.0538e-02,  1.0565e-02,  ...,  3.0559e-04,\n",
      "           9.8467e-05, -2.3842e-07]]], device='cuda:0',\n",
      "       grad_fn=<RsubBackward1>)\n",
      "cosine_dist shape torch.Size([1, 192, 192])\n",
      "mad tensor(0.0050, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "data = torch.load(\"debug_mad_gap.pt\")\n",
    "node_ebd_pt = data[\"node_ebd\"]\n",
    "print(\"node_ebd_pt\", node_ebd_pt)\n",
    "print(\"node_ebd_pt shape\", node_ebd_pt.shape)\n",
    "nframes, nloc, nembed = node_ebd_pt.shape\n",
    "device = node_ebd_pt.device\n",
    "eye_mask = torch.eye(nloc, dtype=torch.bool, device=device).unsqueeze(0).expand(nframes, -1, -1)\n",
    "print(\"eye_mask\", eye_mask)\n",
    "print(\"eye_mask shape\", eye_mask.shape)\n",
    "valid_mask = ~eye_mask\n",
    "print(\"valid_mask\", valid_mask)\n",
    "print(\"valid_mask shape\", valid_mask.shape)\n",
    "\n",
    "    # 2. 添加简化的 _compute_mad 方法\n",
    "\n",
    "\"\"\"计算基础MAD (Mean Average Distance) 用于正则化\n",
    "\n",
    "MAD使用余弦距离衡量节点嵌入表征之间的平均距离:\n",
    "余弦距离 = 1 - 余弦相似度 = 1 - (Hi · Hj) / (|Hi| · |Hj|)\n",
    "\n",
    "Parameters\n",
    "---------- \n",
    "node_ebd : torch.Tensor\n",
    "    节点嵌入表征，形状 [nframes, nloc, embed_dim]\n",
    "    \n",
    "Returns\n",
    "-------\n",
    "torch.Tensor\n",
    "    所有节点对之间的平均余弦距离\n",
    "\"\"\"\n",
    "nframes, nloc, embed_dim = node_ebd.shape\n",
    "device = node_ebd.device\n",
    "\n",
    "# 计算向量范数 |Hi|, |Hj|\n",
    "norms = torch.norm(node_ebd, p=2, dim=-1, keepdim=True)  # [nf, nloc, 1]\n",
    "\n",
    "# 计算点积矩阵 Hi · Hj  \n",
    "dot_products = torch.bmm(node_ebd, node_ebd.transpose(-1, -2))  # [nf, nloc, nloc]\n",
    "\n",
    "# 计算范数乘积矩阵 |Hi| * |Hj|\n",
    "norm_products = torch.bmm(norms, norms.transpose(-1, -2))  # [nf, nloc, nloc]\n",
    "\n",
    "# 余弦距离 = 1 - 余弦相似度\n",
    "cosine_dist = 1.0 - (dot_products / (norm_products + 1e-8))  # 加小值避免除零\n",
    "print(\"cosine_dist\", cosine_dist)\n",
    "print(\"cosine_dist shape\", cosine_dist.shape)\n",
    "# 排除对角线（自己与自己的距离为0）\n",
    "eye_mask = torch.eye(nloc, dtype=torch.bool, device=device).unsqueeze(0).expand(nframes, -1, -1)\n",
    "valid_mask = ~eye_mask\n",
    "\n",
    "# 计算所有有效节点对的平均距离\n",
    "valid_distances = cosine_dist[valid_mask]\n",
    "mad = valid_distances.mean() if len(valid_distances) > 0 else torch.tensor(0.0, device=device)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"mad\", mad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d037af05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node_ebd tensor([[[3., 4.],\n",
      "         [4., 3.],\n",
      "         [3., 4.]],\n",
      "\n",
      "        [[3., 4.],\n",
      "         [4., 3.],\n",
      "         [3., 4.]]])\n",
      "node_ebd shape torch.Size([2, 3, 2])\n",
      "nframes 2\n",
      "nloc 3\n",
      "embed_dim 2\n",
      "device cpu\n",
      "norms tensor([[[5.],\n",
      "         [5.],\n",
      "         [5.]],\n",
      "\n",
      "        [[5.],\n",
      "         [5.],\n",
      "         [5.]]])\n",
      "norms shape torch.Size([2, 3, 1])\n",
      "dot_products tensor([[[25., 24., 25.],\n",
      "         [24., 25., 24.],\n",
      "         [25., 24., 25.]],\n",
      "\n",
      "        [[25., 24., 25.],\n",
      "         [24., 25., 24.],\n",
      "         [25., 24., 25.]]])\n",
      "dot_products shape torch.Size([2, 3, 3])\n",
      "norm_products tensor([[[25., 25., 25.],\n",
      "         [25., 25., 25.],\n",
      "         [25., 25., 25.]],\n",
      "\n",
      "        [[25., 25., 25.],\n",
      "         [25., 25., 25.],\n",
      "         [25., 25., 25.]]])\n",
      "norm_products shape torch.Size([2, 3, 3])\n",
      "cosine_dist tensor([[[0.0000, 0.0400, 0.0000],\n",
      "         [0.0400, 0.0000, 0.0400],\n",
      "         [0.0000, 0.0400, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0400, 0.0000],\n",
      "         [0.0400, 0.0000, 0.0400],\n",
      "         [0.0000, 0.0400, 0.0000]]])\n",
      "cosine_dist shape torch.Size([2, 3, 3])\n",
      "eye_mask tensor([[[ True, False, False],\n",
      "         [False,  True, False],\n",
      "         [False, False,  True]],\n",
      "\n",
      "        [[ True, False, False],\n",
      "         [False,  True, False],\n",
      "         [False, False,  True]]])\n",
      "eye_mask shape torch.Size([2, 3, 3])\n",
      "valid_mask tensor([[[False,  True,  True],\n",
      "         [ True, False,  True],\n",
      "         [ True,  True, False]],\n",
      "\n",
      "        [[False,  True,  True],\n",
      "         [ True, False,  True],\n",
      "         [ True,  True, False]]])\n",
      "valid_mask shape torch.Size([2, 3, 3])\n",
      "valid_distances tensor([0.0400, 0.0000, 0.0400, 0.0400, 0.0000, 0.0400, 0.0400, 0.0000, 0.0400,\n",
      "        0.0400, 0.0000, 0.0400])\n",
      "valid_distances shape torch.Size([12])\n",
      "12\n",
      "mad tensor(0.0267)\n",
      "mad shape torch.Size([])\n",
      "tensor(0.0267)\n",
      "mad tensor(0.0267)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "node_ebd = torch.tensor([[[3.0,4.0],[4.0,3.0],[3.0,4.0]],[[3.0,4.0],[4.0,3.0],[3.0,4.0]]])\n",
    "print(\"node_ebd\", node_ebd)\n",
    "print(\"node_ebd shape\", node_ebd.shape)\n",
    "\n",
    "\"\"\"计算基础MAD (Mean Average Distance) 用于正则化\n",
    "\n",
    "MAD使用余弦距离衡量节点嵌入表征之间的平均距离:\n",
    "余弦距离 = 1 - 余弦相似度 = 1 - (Hi · Hj) / (|Hi| · |Hj|)\n",
    "\n",
    "Parameters\n",
    "---------- \n",
    "node_ebd : torch.Tensor\n",
    "    节点嵌入表征，形状 [nframes, nloc, embed_dim]\n",
    "    \n",
    "Returns\n",
    "-------\n",
    "torch.Tensor\n",
    "    所有节点对之间的平均余弦距离\n",
    "\"\"\"\n",
    "nframes, nloc, embed_dim = node_ebd.shape\n",
    "device = node_ebd.device\n",
    "print(\"nframes\", nframes)\n",
    "print(\"nloc\", nloc)\n",
    "print(\"embed_dim\", embed_dim)\n",
    "print(\"device\", device)\n",
    "# 计算向量范数 |Hi|, |Hj|\n",
    "norms = torch.norm(node_ebd, p=2, dim=-1, keepdim=True)  # [nf, nloc, 1]\n",
    "print(\"norms\", norms)\n",
    "print(\"norms shape\", norms.shape)\n",
    "# 计算点积矩阵 Hi · Hj  \n",
    "dot_products = torch.bmm(node_ebd, node_ebd.transpose(-1, -2))  # [nf, nloc, nloc]\n",
    "print(\"dot_products\", dot_products)\n",
    "print(\"dot_products shape\", dot_products.shape)\n",
    "# 计算范数乘积矩阵 |Hi| * |Hj|\n",
    "norm_products = torch.bmm(norms, norms.transpose(-1, -2))  # [nf, nloc, nloc]\n",
    "print(\"norm_products\", norm_products)\n",
    "print(\"norm_products shape\", norm_products.shape)\n",
    "# 余弦距离 = 1 - 余弦相似度\n",
    "cosine_dist = 1.0 - (dot_products / (norm_products + 1e-8))  # 加小值避免除零\n",
    "print(\"cosine_dist\", cosine_dist)\n",
    "print(\"cosine_dist shape\", cosine_dist.shape)\n",
    "# 排除对角线（自己与自己的距离为0）\n",
    "eye_mask = torch.eye(nloc, dtype=torch.bool, device=device).unsqueeze(0).expand(nframes, -1, -1)\n",
    "print(\"eye_mask\", eye_mask)\n",
    "print(\"eye_mask shape\", eye_mask.shape)\n",
    "valid_mask = ~eye_mask\n",
    "print(\"valid_mask\", valid_mask)\n",
    "print(\"valid_mask shape\", valid_mask.shape)\n",
    "\n",
    "# 计算所有有效节点对的平均距离\n",
    "valid_distances = cosine_dist[valid_mask]\n",
    "print(\"valid_distances\", valid_distances)\n",
    "print(\"valid_distances shape\", valid_distances.shape)\n",
    "print(len(valid_distances))\n",
    "mad = valid_distances.mean() \n",
    "print(\"mad\", mad)\n",
    "print(\"mad shape\", mad.shape)\n",
    "\n",
    "print(cosine_dist.sum()/(nframes*nloc*(nloc-1)))\n",
    "def _compute_mad_v1_manual(node_ebd: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"手动实现版本（当前的高效版）\"\"\"\n",
    "    # 标准化嵌入向量\n",
    "    node_ebd_norm = F.normalize(node_ebd, p=2, dim=-1)  # [nf, nloc, embed_dim]\n",
    "    \n",
    "    # 计算余弦相似度矩阵\n",
    "    cosine_sim = torch.bmm(node_ebd_norm, node_ebd_norm.transpose(-1, -2))\n",
    "    \n",
    "    # 余弦距离 = 1 - 余弦相似度\n",
    "    cosine_dist = 1.0 - cosine_sim\n",
    "    \n",
    "    # Global MAD\n",
    "    global_mad = cosine_dist.sum()/(nframes*nloc*(nloc-1))\n",
    "    \n",
    "    return global_mad\n",
    "\n",
    "mad = _compute_mad_v1_manual(node_ebd)\n",
    "print(\"mad\", mad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "073ae62c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0.],\n",
       "        [0., 1.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eye(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd15567",
   "metadata": {},
   "source": [
    "# nlist 是DeepMD-kit中描述原子邻居关系的关键数据结构：\n",
    "1. 形状: [nframes, nloc, nnei]\n",
    "2. 内容: 每个原子的邻居原子索引\n",
    "3. $填充: 不足的邻居用-1填充$\n",
    "4. 作用: 用于构建邻居掩码，区分邻居和非邻居原子\n",
    "5. 物理意义: 基于距离截断的原子间相互作用关系"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0e14db77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "手动实现: 12.06ms, result: 0.004947\n",
      "内置函数: 46.14ms, result: 0.004947\n",
      "最简洁版: 45.38ms, result: 0.004947\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def _compute_mad_v1_manual(self, node_ebd: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"手动实现版本（当前的高效版）\"\"\"\n",
    "    # 标准化嵌入向量\n",
    "    node_ebd_norm = F.normalize(node_ebd, p=2, dim=-1)  # [nf, nloc, embed_dim]\n",
    "    \n",
    "    # 计算余弦相似度矩阵\n",
    "    cosine_sim = torch.bmm(node_ebd_norm, node_ebd_norm.transpose(-1, -2))\n",
    "    \n",
    "    # 余弦距离 = 1 - 余弦相似度\n",
    "    cosine_dist = 1.0 - cosine_sim\n",
    "    \n",
    "    # Global MAD\n",
    "    global_mad = cosine_dist.mean()\n",
    "    \n",
    "    return global_mad\n",
    "\n",
    "\n",
    "def _compute_mad_v2_builtin(self, node_ebd: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"使用内置cosine_similarity函数\"\"\"\n",
    "    nframes, nloc, embed_dim = node_ebd.shape\n",
    "    \n",
    "    # 扩展维度以计算所有节点对的相似度\n",
    "    node1 = node_ebd.unsqueeze(2)  # [nf, nloc, 1, embed_dim]  \n",
    "    node2 = node_ebd.unsqueeze(1)  # [nf, 1, nloc, embed_dim]\n",
    "    \n",
    "    # 使用内置函数计算余弦相似度\n",
    "    cosine_sim = F.cosine_similarity(node1, node2, dim=-1)  # [nf, nloc, nloc]\n",
    "    \n",
    "    # 余弦距离 = 1 - 余弦相似度\n",
    "    cosine_dist = 1.0 - cosine_sim\n",
    "    \n",
    "    # Global MAD\n",
    "    global_mad = cosine_dist.mean()\n",
    "    \n",
    "    return global_mad\n",
    "\n",
    "\n",
    "def _compute_mad_v3_most_efficient(self, node_ebd: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"最简洁版本（推荐）\"\"\"\n",
    "    nframes, nloc, embed_dim = node_ebd.shape\n",
    "    \n",
    "    # 直接计算所有对的余弦距离\n",
    "    cosine_dist = 1.0 - F.cosine_similarity(\n",
    "        node_ebd.unsqueeze(2),   # [nf, nloc, 1, embed_dim]\n",
    "        node_ebd.unsqueeze(1),   # [nf, 1, nloc, embed_dim]  \n",
    "        dim=-1                   # [nf, nloc, nloc]\n",
    "    )\n",
    "    \n",
    "    return cosine_dist.mean()\n",
    "\n",
    "\n",
    "# 性能测试代码\n",
    "def benchmark_methods():\n",
    "    \"\"\"简单的性能对比\"\"\"\n",
    "    import time\n",
    "    import torch\n",
    "    data = torch.load(\"debug_mad_gap.pt\")\n",
    "    node_ebd = data[\"node_ebd\"]\n",
    "    # 创建测试数据\n",
    "    nframes, nloc, embed_dim = node_ebd.shape\n",
    "    #node_ebd = torch.randn(nframes, nloc, embed_dim, device='cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    methods = [\n",
    "        (\"手动实现\", _compute_mad_v1_manual),\n",
    "        (\"内置函数\", _compute_mad_v2_builtin), \n",
    "        (\"最简洁版\", _compute_mad_v3_most_efficient)\n",
    "    ]\n",
    "    \n",
    "    # 预热\n",
    "    for _, method in methods:\n",
    "        _ = method(None, node_ebd)\n",
    "    \n",
    "    # 测试\n",
    "    for name, method in methods:\n",
    "        torch.cuda.synchronize() if torch.cuda.is_available() else None\n",
    "        start = time.time()\n",
    "        \n",
    "        for _ in range(100):\n",
    "            result = method(None, node_ebd)\n",
    "        \n",
    "        torch.cuda.synchronize() if torch.cuda.is_available() else None\n",
    "        end = time.time()\n",
    "        \n",
    "        print(f\"{name}: {(end-start)*1000:.2f}ms, result: {result:.6f}\")\n",
    "\n",
    "benchmark_methods()  # 取消注释来运行测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c894451f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node_ebd.min() tensor(-0.1624, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "node_ebd.max() tensor(1.1052, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "node_ebd_norm.min() tensor(-0.0370, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "node_ebd_norm.max() tensor(0.2571, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "cosine_sim.max() tensor(1.0000, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "cosine_sim.mean() tensor(0.9951, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.0131, device='cuda:0', grad_fn=<MaxBackward1>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "data = torch.load(\"debug_mad_gap.pt\")\n",
    "node_ebd = data[\"node_ebd\"]\n",
    "# 创建测试数据\n",
    "nframes, nloc, embed_dim = node_ebd.shape\n",
    "print(\"node_ebd.min()\", node_ebd.min())\n",
    "print(\"node_ebd.max()\", node_ebd.max())\n",
    "node_ebd_norm = F.normalize(node_ebd, p=2, dim=-1)\n",
    "print(\"node_ebd_norm.min()\", node_ebd_norm.min())\n",
    "print(\"node_ebd_norm.max()\", node_ebd_norm.max())\n",
    "cosine_sim = torch.bmm(node_ebd_norm, node_ebd_norm.transpose(-1, -2))\n",
    "cosine_sim.min()\n",
    "print(\"cosine_sim.max()\", cosine_sim.max())\n",
    "cosine_sim.max()\n",
    "print(\"cosine_sim.mean()\", cosine_sim.mean())\n",
    "\n",
    "cosine_dist = 1.0 - cosine_sim\n",
    "cosine_dist.min()\n",
    "cosine_dist.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b926516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1, -1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlist\n",
    "nlist[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9d1cee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine_dist tensor([[[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[-1.1921e-07,  9.2763e-04,  2.5233e-03],\n",
      "         [ 9.2763e-04,  5.9605e-08,  3.9136e-04],\n",
      "         [ 2.5233e-03,  3.9136e-04,  0.0000e+00]]])\n"
     ]
    }
   ],
   "source": [
    "# 使用PyTorch内置函数\n",
    "cosine_sim = F.cosine_similarity(\n",
    "    node_ebd.unsqueeze(2),  # [nf, nloc, 1, embed_dim] \n",
    "    node_ebd.unsqueeze(1),  # [nf, 1, nloc, embed_dim]\n",
    "    dim=-1  # 在embed_dim维度计算\n",
    ")  # [nf, nloc, nloc]\n",
    "\n",
    "cosine_dist = 1.0 - cosine_sim\n",
    "print(\"cosine_dist\", cosine_dist)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
